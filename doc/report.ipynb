{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review and implementation of the stochastic approximate proximal point method\n",
    "\n",
    "#### Team 5. Park, Sungmin, Lee, Yoonhyung and Han, Seungji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Stochastic gradient method\n",
    "\n",
    "Consider the following optimization problem.\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\underset{x\\in\\mathcal{X}}{\\text{minimize }} &F(x) = \\mathbb{E}_P[f(x;S)] = \\int_{\\mathcal{S}}f(x;s)dP(s)\\tag{1} \\\\\n",
    "    \\text{subject to } &x \\in \\mathcal{X}.\n",
    "\\end{align}$$\n",
    "\n",
    "In this problem, the set $\\mathcal{S}$ is a sample space, and for given $s \\in \\mathcal{S}$, the function $f(\\cdot;s) : \\mathbf{R}^n \\rightarrow \\mathbf{R}$ is a closed, convex, and subdifferentiable where $\\mathcal{X}$ is a closed convex set.\n",
    "\n",
    "In stochastic optimization methods, a $S_k$ is sampled independently and identically from $P$ and information of the function $f(\\cdot;S_k)$ is used in each update.\n",
    "\n",
    "For example, the update equation of **the stochastic (sub)gradient method (SGM)** is given by\n",
    "\n",
    "$$\\begin{align}\n",
    "    x_{k+1} := x_k - \\alpha g_k \\text{ for some } g_k \\in \\partial f(x_k;S_k).\\tag{2}\n",
    "\\end{align}$$\n",
    "\n",
    "SGM is widely and successfully used in various areas of large-scale optimization problems. However, its sensitivity to the choice of initial step size and instability in convegernce can be obstacles in practical appliance.\n",
    "\n",
    "[//]: # \"Despite of its wide use in numerous areas and its success in large-scale optimization problem, difficulties with stochastic gradient method are well-known. It is sensitive to the choice of step size and can diverge easily.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Approximate proximal point (APROX) family\n",
    "\n",
    "SGM can be viewed as a sequential optimization procedure of random models. Let $f^\\text{SGM}_{x_k}(x;S_k) := f(x_k;S_k) + \\langle g_k, x-x_k\\rangle$ and $x_k^{SGM}$ is the $k$-th iterate from SGM. Then, the update $(2)$ can be expressed as\n",
    "\n",
    "$$\\begin{align}\n",
    "    x_{k+1}^{SGM} = \\underset{x \\in \\mathcal{X}}{\\text{argmin}} \\left\\{ f^\\text{SGM}_{x_k}(x;S_k) + \\frac{1}{2 \\alpha_k} \\|x-x_k\\|_2^2 \\right\\}.\n",
    "\\end{align}$$\n",
    "\n",
    "Since $f^\\text{SGM}_{x_k}(x;S_k)$ is a linear approximation of $f(x;S_k)$, one can consider another approximation of $f(x;S_k)$ so that extend to a new stochastic optimization method. Based on this idea, Hilal Asi and John C. Duchi proposed a new family of stochastic optimization methods called **the approximate proximal point (APROX) method** [1]. The update algorithm of the APROX method is following:\n",
    "\n",
    "$$\\begin{align}\n",
    "    x_{k+1} := \\underset{x \\in \\mathcal{X}}{\\text{argmin}} \\left\\{ f_{x_k}(x;S_k) + \\frac{1}{2 \\alpha} \\|x - x_k \\|_2^2 \\right\\}.\\tag{3}\n",
    "\\end{align}$$\n",
    "\n",
    "The function $f_x(\\cdot;s)$, which is called **a model of $f(\\cdot;s)$ at the point $x$**, satisfies the follwing conditions:\n",
    "\n",
    "(C1) The function $y \\mapsto f_x(y;s)$ is convex and subdifferentiable on $\\mathcal{X}$.\n",
    "\n",
    "(C2) The function $f_x$ satisfies the equality $f_x(y;s) = f(x;s)$ and \n",
    "\n",
    "$$\\begin{align}\n",
    "    f_x(y;s) \\le f(y;s) \\text{ for all } y.\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Stochastic optimization methods that are  included in APROX family\n",
    "\n",
    "In here, we provide a catalogue of a few models in APROX family.\n",
    "\n",
    "#### 1.3.1. Stochastic proximal point methods\n",
    "\n",
    "Let $f_{x_k}(x;S_k) := f(x;S_k)$. That is, we use full model $f(\\cdot;S_k)$ as its approximation. Then, the update method is given by\n",
    "\n",
    "$$\\begin{align}\n",
    "    x_{k+1} := \\underset{x \\in \\mathcal{X}}{\\text{argmin}} \\left\\{ f(x;S_k) + \\frac{1}{2 \\alpha_k} \\|x - x_k \\|_2^2 \\right\\}.\\tag{4}\n",
    "\\end{align}$$\n",
    "\n",
    "This optimization method is called **the stochastic proximal point method**, which is a stochastic version of the proxiaml point method.\n",
    "\n",
    "#### 1.3.2. Stochastic gradient methods\n",
    "\n",
    "Let $f_{x_k}(x;S_k) := f(x_k;S_k) + \\langle g_k, x-x_k\\rangle$. Then the stochastic gradient method can be expressed as APROX family and the update is $(2)$.\n",
    "\n",
    "#### 1.3.3. Truncated models\n",
    "\n",
    "Suppose that we know the infimum value of $f(x;s)$ for a fixed $s \\in \\mathcal{S}$ and let $f_{x_k}(x;S_k) := \\max \\left\\{f(x_k;S_k) + \\langle g_k, x-x_k\\rangle,  \\displaystyle\\inf_{z \\in \\mathcal{X} (z;s)}f(z;s)\\right\\}$. This model is called the truncated model.\n",
    "\n",
    "#### 1.3.4. Bundle models\n",
    "\n",
    "One may consider less accurate models than the stochastic proximal point methods called Bundle methods [3,4].\n",
    "\n",
    "We begin with $f_x^0(y;s) := f_x^{\\text{SGM}}(y;s)$ and iteratively construct the lower piecewise-linear models\n",
    "\n",
    "$$\\begin{align}\n",
    "    x_{\\alpha}^i &:= \\underset{y \\in \\mathcal{X}}{\\text{argmin}}\\left\\{f_x^{i-1}(y;s) + \\frac{1}{2\\alpha}\\|y-x\\|_2^2\\right\\} \\\\\n",
    "    f_x^i(y;s) &:= \\max\\left\\{f_x^{i-1}(y;s), f_{x_{\\alpha}^i}^{\\text{SGM}}(y;s) \\right\\}.\n",
    "\\end{align}$$\n",
    "\n",
    "With proper termination, we set $f_x(y;s) := f_x^i(y;s)$. For the experiment we used $i=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Detailed update method of APROX family\n",
    "For the truncated model and the bundle model, the detailed updates of method are not simple as those of SGM. In this part, we propose the detailed updates of the truncated model and the bundle model.\n",
    "\n",
    "#### 1.4.1. Stochastic proximal point method\n",
    "The stochstic proximal method uses proximal operator in each update. However, the function $f$ is not easily proximable in many applications. One could calculate the proximal operator by solving p-dimensional convex optimization problem in each update, but this can yield huge computing cost. Forfunately, we can calculate the proximal operator by solving one-dimensional convex optimization problem especially when the function $f$ is the form of generalized linear model. \n",
    "\n",
    "Let $f(x;s) \\equiv g(a'x;s;)$. The update equation of the stochastic proximal point method can be expressed alternatively as\n",
    "\\begin{align}\n",
    "x_{k+1} := x_k - \\alpha_k \\nabla f(x_{k+1} ; S_k)\n",
    "\\end{align}\n",
    "\n",
    "Note that $x_{k+1}$ appears on both the left hand side and the right hand side of the update equation. Compared to the stochastic gradient method, the stochastic proximal point method uses the gradient at $x_{k+1}$ instead of the gradient at $x_k$. Since the function $f$ is the form of generalized linear model, $\\nabla f(x_k ;S_k) = g'(a'x_k;S_k)a$ and $\\nabla f(x_{k+1} ;S_k) = g'(a'x_{k+1};S_k)a$. That is, two gradient have the same direction. Consequently, one can implement the stochastic proximal point method by solving following one-dimensial convex optimization problem.\n",
    "\\begin{align}\n",
    "\\min_{t}\\{ f(x_k - \\alpha t \\nabla f(x_k ; S_k)) + \\frac{\\alpha_k^2 t^2}{2} \\|\\nabla f(x_k;S_k) \\|_2^2\\}\\tag{5}\n",
    "\\end{align}\n",
    "\n",
    "In addition, Toulis and Airoldi (2017) showed that $t \\in [0,1]$ in (5). Hence, we can implement the stochastic proximal point method by the following procedure [2]:\n",
    "\n",
    "a) Let $t_k = \\text{argmin}_{t \\in [0,1]}\\{ f(x_k - \\alpha t \\nabla f(x_k ; S_k)) + \\frac{\\alpha_k^2 t^2}{2} \\|\\nabla f(x_k;S_k) \\|_2^2\\}$\n",
    "\n",
    "b) $x_{k+1} := x_k - \\alpha_k t_k \\nabla f(x_k ; S_k)$\n",
    "\n",
    "#### 1.4.2. Truncated Model\n",
    "\n",
    "Suppose that $\\inf f(x;s) = 0$. (Many losses like $\\ell$2 loss already satisfy this condition.)\n",
    "\n",
    "Then, the model is $f_x(y;s) := [f^{\\text{SGM}}_x(y;s)]_+ = \\max\\{0, f^{\\text{SGM}}_x(y;s)\\}$.\n",
    "\n",
    "The update is\n",
    "\n",
    "$$\n",
    "x_{k+1} =\n",
    "\\begin{cases}\n",
    "    \\bar{x}_{k+1}, &\\text{if}~~ f_x^{\\text{SGM}}(\\bar{x}_{k+1};s) \\ge 0\\tag{6} \\\\\n",
    "    P_C(x_k) = x_k - \\frac{f(x_k;s)}{\\|\\nabla f(x_k;s)\\|_2^2}\\nabla f(x_k;s), &\\text{o.w.}\n",
    "\\end{cases},\n",
    "$$\n",
    "\n",
    "where $\\bar{x}_{k+1} = x_k - \\alpha_k \\nabla f(x_k;s)$ and $C = \\{x \\in \\mathbb{R}^n: f^{\\text{SGM}}_{x_k}(x;s)=0\\}$.\n",
    "\n",
    "Since $f_x^{\\text{SGM}}(\\bar{x}_{k+1};s) < 0 \\iff \\frac{f(x_k;s)}{\\|\\nabla f(x_k;s)\\|_2^2} < \\alpha_k $, $(6)$ can be rewritten as\n",
    "\n",
    "$$x_{k+1} = x_k - \\min\\left\\{\\alpha_k, \\frac{f(x_k;s)}{\\|\\nabla f(x_k;s)\\|_2^2} \\right\\}\\nabla f(x_k;s)\\tag{7}$$\n",
    "\n",
    "#### 1.4.3. Bundle Model\n",
    "\n",
    "To build the update of the bundle model, we first let $f_x^0(y;s) := f_x^{\\text{SGM}}(y;s)$.\n",
    "\n",
    "The model function for the bundle model is iteratively construct in each update as following.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    x_{\\alpha}^i &:= \\underset{y \\in \\mathcal{X}}{\\text{argmin}}\\left\\{f_x^{i-1}(y;s) + \\frac{1}{2\\alpha}\\|y-x\\|_2^2\\right\\} \\\\\n",
    "    f_x^i(y;s) &:= \\max\\left\\{f_x^{i-1}(y;s), f_{x_{\\alpha}^i}^{\\text{SGM}}(y;s) \\right\\}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "With some proper termination, we let $f_x(y;s) := f_x^i(y;s)$.\n",
    "\n",
    "Especially, we describe how we get the detailed update method for $i=1$.\n",
    "\n",
    "Given $x_k$, let $y_k = x_k - \\alpha_k \\nabla f(x_k;s)$ be the SGM update.\n",
    "\n",
    "$f_{x_k}(x;s) = \\max\\{f_{x_k}^{\\text{SGM}}(x;s), f_{y_k}^{\\text{SGM}}(x;s) \\}$.\n",
    "\n",
    "From\n",
    "$$\n",
    "\\begin{align}\n",
    "    f(x_k) + \\langle \\nabla f(x_k), y_k-x_k\\rangle \\le f(y_k) = f(y_k) + \\langle \\nabla f(y_k), y_k-y_k\\rangle,\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "we can see that bundle update will not lie in  $\\left\\{x:f(x_k)+ \\langle \\nabla f(x_k), x-x_k\\rangle >  f(y_k) + \\langle \\nabla f(y_k), x-y_k\\rangle\\right\\}$.\n",
    "\n",
    "\n",
    "We can restrict our focus in the region $\\left\\{x:f(x_k)+ \\langle \\nabla f(x_k), x-x_k\\rangle \\le  f(y_k) + \\langle \\nabla f(y_k), x-y_k\\rangle\\right\\}$.\n",
    "\n",
    "Let $\\bar{x}_{k+1} := x_k - \\alpha_n\\nabla f(y_k)$.\n",
    "\n",
    "If, $\\bar{x}_{k+1} \\in \\left\\{x:f_{x_k}^{\\text{SGM}}(x;s) \\le f_{y_k}^{\\text{SGM}}(x;s) \\right\\}$, then $x_{k+1}=\\bar{x}_{k+1}$.\n",
    "\n",
    "If not, we have to solve\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\underset{x\\in\\mathcal{X}}{\\text{minimize}} \\quad &\\frac{1}{2\\alpha_k}\\|x-x_k\\|_2^2 +f_{x_k}^{\\text{SGM}}(x;s) \\\\\n",
    "    \\text{subject to} \\quad &f_{x_k}^{\\text{SGM}}(x;s) =f_{y_k}^{\\text{SGM}}(x;s),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "i.e.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\underset{x\\in\\mathcal{X}}{\\text{minimize}} \\quad &\\frac{1}{2\\alpha_k}\\|x-x_k\\|_2^2 +\\langle \\nabla f(x_k), x-x_k \\rangle + f(x_k) \\\\\n",
    "    \\text{subject to} \\quad &\\langle \\nabla f(x_k), x-x_k \\rangle + f(x_k) =\\langle \\nabla f(y_k), x-y_k \\rangle + f(y_k).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Form a Lagrangian\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathcal{L} &= \\frac{1}{2\\alpha_k}\\|x-x_k\\|_2^2 +\\langle \\nabla f(x_k), x-x_k \\rangle + f(x_k) + \\lambda\\left(\\langle \\nabla f(y_k), x-y_k \\rangle + f(y_k) - \\langle \\nabla f(x_k), x-x_k \\rangle - f(x_k) \\right) \\\\\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial x} &= \\frac{1}{\\alpha_k}(x-x_k) + \\nabla f(x_k) + \\lambda (\\nabla f(y_k) - \\nabla f(x_k)),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which yields update,\n",
    "\n",
    "$$\n",
    "x_{k+1} = x_k - \\alpha_k \\left(\\nabla f(x_k) + \\lambda ~(\\nabla f(y_k) - \\nabla f(x_k)) \\right).\n",
    "$$\n",
    "\n",
    "From the equality constraint, $\\lambda$ must satisfy\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\langle \\nabla f(x_k), x_{k+1}-x_k \\rangle + f(x_k) &=\\langle \\nabla f(y_k), x_{k+1}-y_k \\rangle + f(y_k) \\\\\n",
    "\\langle \\nabla f(x_k), - \\alpha_k \\left(\\nabla f(x_k) + \\lambda ~(\\nabla f(y_k) - \\nabla f(x_k)) \\right) \\rangle + f(x_k) &=\\langle \\nabla f(y_k), -\\alpha_k \\lambda ~(\\nabla f(y_k) - \\nabla f(x_k)) \\rangle + f(y_k).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Solving for $\\lambda$, we obtain\n",
    "$$\n",
    "\\lambda = \\frac{f(y_k)-f(x_k)+\\alpha_k\\|\\nabla f(x_k)\\|_2^2}{\\alpha_k\\|\\nabla f(y_k) - \\nabla f(x_k)\\|^2}.\n",
    "$$\n",
    "\n",
    "Hence the update equation,\n",
    "$$\n",
    "x_{k+1} =\n",
    "\\begin{cases}\n",
    "    \\bar{x}_{k+1}, &\\text{if}~~ \\bar{x}_{k+1} \\in \\left\\{x:f_{x_k}^{\\text{SGM}}(x;s) \\le f_{y_k}^{\\text{SGM}}(x;s) \\right\\}\\tag{8} \\\\\n",
    "    x_k - \\alpha_k \\left((1-\\lambda)\\nabla f(x_k) + \\lambda\\nabla f(y_k)) \\right), &\\text{o.w.}\n",
    "\\end{cases}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Theorems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Assumptions\n",
    "\n",
    "Assume that following assumptions hold.\n",
    "\n",
    "(A1) The set $\\mathcal{X}^* := \\underset{x \\in \\mathcal{X}}{\\text{argmin}}\\{ F(x) \\}$ is non-empty, and there exists $\\sigma^2 < \\infty$ such that $\\mathbb{E}[\\|f'(x^*;S)\\|_2^2] \\le \\sigma^2 $ for $x^* \\in \\mathcal{X}^*$ and all measurable selections $f'(x^*;s) \\in \\partial f(x;s)$.\n",
    "\n",
    "(A2) There exists a non-decreasing function $G_{big} : \\mathbf{R}_+ \\rightarrow [0,\\infty)$ such that for all $x \\in \\mathcal{X}$ and measurable selections $f'(x;s) \\in \\partial f(x;s)$, $\\mathbb{E}[\\|f'(x;S) \\|^2] \\le G_{big}(dist(x, \\mathcal{X}^*))$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Convergence of APROX family methods\n",
    "**Theorem 1. ** Let $\\{\\alpha_k\\}$ is a sequence of step sizes such that $\\alpha_k > 0 \\text{ for all } k, \\sum_{k=1}^{\\infty} \\alpha_k = \\infty \\text{, and } \\sum_{k=1}^{\\infty} \\alpha_k < \\infty$. Let the iterates $x_k$ be generated by APROX method and $F^* = \\inf_{x \\in \\mathcal{X}} F(x)$. On the event that $\\sup_k dist(x_k, \\mathcal{X}) < \\infty$, with probability $1$ both $\\sum_k \\alpha_k(F(x_k) - F^*) < \\infty$, and the iterates $x_k$ converge: there exists $x^* \\in \\mathcal{X}^*$ such that $\\|x_k - x^* \\| \\rightarrow 0 \\text{ a.s.}$ and $F(x_k) \\rightarrow F(x^*) \\text{ a.s.}$\n",
    "\n",
    "The last sentence of the Theorem 1 means that $x_k$ converges to the minimum point on the event that $\\sup_k dist(x_k, \\mathcal{X}) < \\infty$ with probabilty $1$. However, on the event that $\\sup_k dist(x_k, \\mathcal{X}) < \\infty$, the almost surely convergence of $x_k$ cannot be guaranteed. The condition $\\sup_k dist(x_k, \\mathcal{X}) < \\infty$ is called the stability condition. More detailed explanation for **the stability condition** is introduced in the next subsection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. The stability condition\n",
    "\n",
    "**Definition. (Stability)** Let $\\{\\alpha_k\\}$ be a sequence of step sizes  such that $\\sum_k \\alpha_k^2$, $\\mathcal{F}$ is a collection of functions $f : \\mathcal{X} \\times \\mathcal{S}$, and $\\mathcal{P}$ is a collection of probability measures. For given $\\mathcal{F}$ and $\\mathcal{P}$, let $F(x) = \\mathbb{E}_P[f(x;S)]$ and $\\mathcal{X}^* = \\underset{x \\in \\mathcal{X}^*}{\\text{argmin}} F(x)$. An algorithm generating iterates $x_k$ is **stable in probability** for the collection of $(\\mathcal{F}, \\mathcal{P})$ if \n",
    "\n",
    "$$\\begin{align}\n",
    "    \\sup_k dist(x_k, \\mathcal{X}^*) < \\infty \\text{ with probability 1.}\n",
    "\\end{align}$$\n",
    "\n",
    "for all $f \\in \\mathcal{F}$ and $P \\in \\mathcal{P}$.\n",
    "\n",
    "To satisfy the stability condition, the following assumption is needed:\n",
    "\n",
    "(A3) Let $x_{\\alpha} := \\underset{x \\in \\mathcal{X}^*}{\\text{argmin}}\\{ f_{x_0} (x;s) + \\frac{1}{2 \\alpha} \\|x - x_0 \\|_2^2 \\}$. For some $\\epsilon > 0$. There exists a function $C : \\mathcal{S} \\rightarrow \\mathbf{R}_+$ with $\\mathbb{E}[C(\\mathcal{S})] < \\infty$ such that for all $x_0 \\in \\mathcal{X}$, the updated point $x_{\\alpha}$ and function $f_{x_0}(\\cdot;s)$ satisfy\n",
    "\n",
    "$$\\begin{align}\n",
    "    f(x_{\\alpha};s) \\le f_{x_0}(x_{\\alpha};s) + \\frac{1-\\epsilon}{2 \\alpha} \\|x_{\\alpha} -  x_0\\|_2^2 + C(\\mathcal{S}) \\alpha.\n",
    "\\end{align}$$\n",
    "\n",
    "It can be shown that the stochastic proximal point method and the bundle model satisfy the assumption (A3), but the stochastic gradient method and the truncated model do not satisfy the assumption (A3). Hence, we can only guarantee the almost surely convergence for the proximal point method and the bundle model but not for the stochastic gradient method and the truncated model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Asymptotic normality\n",
    "\n",
    "For asymptotic normality of the APROX family, the following assumption is needed.\n",
    "\n",
    "(A4) The function $F$ and $f$ satisfy the following.\n",
    "\n",
    "* The function $F$ is $\\mathcal{C}^2$ in a neighborhood of $x^* = \\underset{x \\in \\mathcal{X}}{\\text{argmin}} F(x)$, and $\\nabla^2 F(x^*) \\succ 0$.\n",
    "\n",
    "* There exists $\\epsilon > 0$ such that $f(\\cdot;s)$ is $L(s)$-smooth on the set $\\mathcal{X}_{\\epsilon}^* := \\{x: \\|x - x^* \\| \\le \\epsilon \\}$. That is, $x \\mapsto \\nabla f(x;s)$ is $L(s)$-Lipschitz on $\\mathcal{X}_{\\epsilon}^*$, and $\\mathbb{E}[L(S)^2] = L^2 < \\infty$.\n",
    "\n",
    "**Theorem 2.** Assume that (A4) holds and let the iterates $x_k$ the iterates are bounded: with probability 1, $\\displaystyle\\sup_k\\|x_k \\| < \\infty$. Then,\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\frac{1}{\\sqrt{k}} \\sum_{i=1}^k (x_i - x^*) \\rightarrow \\text{N}(0, \\nabla^2 F(x^*)^{-1} \\text{Cov}(\\nabla f(x^*;S))\\nabla^2 F(x^*)^{-1}).\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Fast convergence for easy problems\n",
    "For some special problems called 'easy problems', we can derive faster convergence rate of the stochastic proximal point method and the truncated model compared to 'not easy' problems. we say that the problem is easy if the problem has a shared minimizer.\n",
    "\n",
    "** Definition. (Shared minimizer) ** Let $F(x) := \\mathbb{E}_P[f(x;S)]$. Then, $F$ is **easy to optimize** if we have \n",
    "\n",
    "$$\\begin{align}\n",
    "    \\inf_{x \\in \\mathcal{X}} f(x;s) = f(x^*;s)\n",
    "\\end{align}$$\n",
    "\n",
    "for each $x^* \\in \\mathcal{X}^* := \\underset{x \\in \\mathcal{X}}{\\text{argmin}} F(x)$ and $P$-almost all $s \\in \\mathcal{S}$.\n",
    "\n",
    "We can consider two further assumptions for easy problems.\n",
    "\n",
    "(A5) (Expected sharp growth) There exist constants $\\lambda_0, \\ \\lambda_1 > 0$ such that for all $\\alpha \\in \\mathbf{R}_+$ and $x \\in \\mathcal{X}$ and $x^* \\in \\mathcal{X}^*$,\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\mathbb{E}\\left[\\min\\left\\{\\alpha [\\|f(x;S) - f(x^*;S)\\|], \\frac{{f(x;S) - f(x^*;S)}^2}{\\|f'(x;S) \\|)2^2} \\right\\}\\right] \\ge dist(x, \\mathcal{X}^*) \\min \\{\\lambda_0 \\alpha, \\lambda_1 dist(x,\\mathcal{X}^*) \\}.\n",
    "\\end{align}$$\n",
    "\n",
    "(A6) (Quadratic growth with shared minimizers) There exist constants $\\lambda_0, \\ \\lambda_1 > 0$ such that for all $x \\in \\mathcal{X}$ and $\\alpha > 0$,\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\mathbb{E}\\left[(f(x;S) - f(x^*;S)) \\min \\left\\{\\alpha, \\frac{f(x;S) - f(x^*;S)}{\\|f'(x;S)\\|_2^2} \\right\\}\\right] \\ge \\min\\{\\lambda_0 \\alpha, \\lambda_1 \\} dist(x, \\mathcal{X}^*)^2.\n",
    "\\end{align}$$\n",
    "\n",
    "For (A5) and (A6), we can derive different convergence rates with respect to each assumption.\n",
    "\n",
    "**Theorem 3.** Let $F$ be easy to optimize, assumption (A5) holds and $x_k$ be generated by the stochastic proximal point method or the truncated model. Define $K_0 := [(\\lambda_0 \\alpha_0 / (\\lambda_1 dist(x_1,\\mathcal{X^*})))^{1/\\beta}]$. Then\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\mathbb{E}[dist(x_{k+1}, \\mathcal{X}^*)^2] \\le \\exp\\left(- \\lambda_1 \\min \\{k, K_0 \\} - \\frac{\\lambda_0}{dist(x_1,\\mathcal{X}^*)} \\sum_{i = K_0 + 1}^k \\alpha_i\\right) dist(x_1, \\mathcal{X}^*)^2\n",
    "\\end{align}$$\n",
    "\n",
    "and with probability 1, we have the linear convergence\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\underset{k \\rightarrow \\infty}{\\text{limsup}} \\frac{dist(x_k, \\mathcal{X}^*)^2}{(1-\\lambda_1)^k} < \\infty.\n",
    "\\end{align}$$\n",
    "\n",
    "**Theorem 4.** Let $F$ be easy to optimize, assumption (A6) holds and $x_k$ be generated by the stochastic proximal point method or the truncated model. Define $K_0 = [(\\lambda_0 \\alpha_0/\\lambda_1)^{1/\\beta}]$. Then\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\mathbb{E}[dist(x_{k+1}, \\mathcal{X}^*)^2] \\le \\exp\\left(-\\lambda_1 \\min\\{k, K_0 \\} - \\lambda_0 \\sum_{K_0 + 1}^{k} \\alpha_i\\right) dist(x_1,\\mathcal{X}^*)^2.\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiments\n",
    "\n",
    "In this section, we present implemented numerical results solving\n",
    "\n",
    "* Linear regression\n",
    "\n",
    "* Logistic regression\n",
    "\n",
    "* Multiclass hinge loss\n",
    "\n",
    "* Poisson regression\n",
    "\n",
    "with\n",
    "\n",
    "* Stochastic gradient method (SGM): uses the linear model (2)\n",
    "\n",
    "* Proximal: uses the full model (4)\n",
    "\n",
    "* Truncated: uses the lower truncated model (6)\n",
    "\n",
    "* Bundle: uses the bundle model with $i = 1$, that is, (7).\n",
    "\n",
    "Within each of our experiments, we run each model-based iteration (3) for 1000 total iterations across multiple initial step sizes $\\alpha_0$. For a fixed accuracy $\\epsilon > 0$, we record the number of steps $k$ required to achieve $F(x_k) - F(x^\\star)\\leq\\epsilon$. 0.05 is used for $\\epsilon$ in these experiments. We perform 100 experimetns for each initial step-size choice, reporting the median of the time-to-$\\epsilon$-accuracy; the shaded areas in each plot cover the 5th to 95th percentile of convergece times. We only consider the single-sample batch size setting since Asi and Duchi noted that using mini-batches does not improve the robustness of SGM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Linear regression\n",
    "\n",
    "Let $A\\in\\mathbb{R}^{m\\times n}, b\\in\\mathbb{R}^m$ and $F(x) = \\frac{1}{2m}\\|Ax - b\\|_2^2$, where $x^\\star\\sim N(0, I_n)\\in\\mathbb{R}^n$ and $b = Ax^\\star + \\sigma v$ for $v\\sim N(0, I_m)$. $\\sigma = 0$ for noiseless experiments and $\\sigma = \\frac{1}{2}$ otherwise.\n",
    "\n",
    "In here, $A$ is generated as $A = QD$, where $Q\\in\\mathbb{R}^{m\\times n}$ has uniformly random orthogonal columns, and $D = \\text{diag}(1, 1 + (\\kappa - 1)/(n - 1), \\cdots, \\kappa)$ is a diagonal matrix with linearly spaced entries between $1$ and a desired condition number $\\kappa\\geq1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<tr>\n",
    "    <td><img src=\"fig/figure2a.svg\" width=\"450\" height=\"350\"></td>\n",
    "    <td><img src=\"fig/figure2b.svg\" width=\"450\" height=\"350\"></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><img src=\"fig/figure3a.svg\" width=\"450\" height=\"350\"></td>\n",
    "    <td><img src=\"fig/figure3b.svg\" width=\"450\" height=\"350\"></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Figure 2, we plot the results of experiments on well-conditioned problems, which use matrices $A$ with condition number $\\kappa(A) = 1$, while Figure 3 shows identical results except that we use condition number $\\kappa(A) = 15$. Plot (a) of each figure demonstrates the results for the noiseless setting with $\\sigma = 0$.\n",
    "\n",
    "In Figure 2(a), we see that the SGM has good performance in some range, while the truncated and the proximal point models yields better convergence. THe bundle model shows somewhat more robustness than SGM, but it sill diverges for larger step sizes.\n",
    "\n",
    "In the noisy cases, plot (b) in each figure, the results are similar, except the full proximal model is somewhat less robust to step-size choice.\n",
    "\n",
    "Figure 3 tells a similar story to Figure 2, except that the SGM is essentially not convergent. These plots suggest that the reliance on SGM in much of the statistical and machine learning literature may be misplaced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Logistic regression\n",
    "\n",
    "Let the data pairs $(a_i, b_i)\\in\\mathbb{R}^n\\times\\{\\pm1\\}$, and we wish to minimize\n",
    "\n",
    "$$\\begin{align*}\n",
    "    F(x) := \\dfrac{1}{m}\\sum_{i = 1}^m f(x;(a_i, b_i)),\n",
    "\\end{align*}$$\n",
    "\n",
    "where $f(x;(a_i, b_i)) = \\log\\left(1 + e^{-b\\langle a, x\\rangle}\\right)$.\n",
    "\n",
    "The data is generated as follows: sample $a_i\\overset{\\text{iid}}{\\sim} N(0, I_n)$ and $u^\\star\\sim N(0, I_n)$, labeling $b_i = \\text{sign}(\\langle a_i, u^\\star\\rangle)$. In noisy setting each label's sign independently with probability $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td><img src=\"fig/figure4a.PNG\" width=\"450\" height=\"350\"></td>\n",
    "    <td><img src=\"fig/figure4b.PNG\" width=\"450\" height=\"350\"></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><img src=\"fig/figure5a.PNG\" width=\"450\" height=\"350\"></td>\n",
    "    <td><img src=\"fig/figure5b.PNG\" width=\"450\" height=\"350\"></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present the results of this experiment in Figure 4 and 5, including plots for both the noiseless (perfectly separated) and noisy cases (plots (a) and (b) in each figure, respectively), where Figure 5 displays results when the condition number of the data matrix $A$ is $\\kappa(A) = 15$. These plots demonstrate similar results to those in the preceding sections, though there are a few differences.\n",
    "\n",
    "First, in the noiseless setting, there is no optimizer $x^\\star$, as the optimal value is $\\lim_{t\\rightarrow\\infty}F(tu^\\star)=0$, yet still we see the benefits of the more accurate models in Figures 4(a) and 5(a). Moreover, the truncated and proximal models exhibit a wider range of convergent step sizes than the simple SGM does even in the noisy case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Multiclass hinge loss\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    F(X) &= \\frac{1}{m}\\sum_{i=1}^{m} \\max_{j\\ne l_i} [1+ \\langle a_i, x_j - x_{l_i} \\rangle]_+ \\\\\n",
    "    f(X;a,l) &= \\max_{j\\ne l} [1+ \\langle a, x_j - x_{l} \\rangle]_+\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Since $f(X;a,l)$ is not differentiable, we will use subgradient of $f(X;a,l)$.\n",
    "\n",
    "Let\n",
    "$$\n",
    "    g(X;a,l) = \\begin{bmatrix}\\mathbf{0} & \\cdots &\\mathbf{a} &\\cdots & -\\mathbf{a} & \\cdots & \\mathbf{0} \\end{bmatrix} = \\mathbf{a}\\mathbf{v}^T\n",
    "$$\n",
    "for a vector $\\mathbf{v} \\in \\mathbb{R}^K$ s.t.\n",
    "$$\n",
    "v_i = \\begin{cases}\n",
    "1, &i=\\min\\{j:[1+ \\langle a, x_j - x_{l} \\rangle]_+ = \\max_{j\\ne l} [1+ \\langle a, x_j - x_{l} \\rangle]_+\\} \\\\\n",
    "-1, &i = l \\\\\n",
    "0, &\\text{o.w.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Then $g(X;a,l) \\in \\partial f(X;a,l)$.\n",
    "\n",
    "Let $A = [a_i|\\cdots|a_m]^T \\in \\mathbb{R}^{m\\times n}$ be the data matrix and $U = [u_1|\\cdots|u_K] \\in \\mathbb{R}^{n\\times K}$ be the classifier. \n",
    "\n",
    "We generate our data matrix $A\\in \\mathbb{R}^{m\\times n}$ and optimal classifer $U^{\\star}$ using i.i.d. $N(0,I_n)$ samples for each entry. We label $l_i$ s according to our correct classfier $U^{\\star}$ where $l_i = \\text{argmax}_j \\langle u_j^{\\star}, a_i \\rangle$. In the noisy setting, labels are changed with probability $p$. When a label is chosen to add noise, we select a random label uniformly from 1 to $K$.\n",
    "\n",
    "Although the original experiment in the paper used $m=2,000$ samples with dimension $n=15$ and $K=10$, we found that 1,000 iteration are not even close to enough to approach the optimal value. Without proper starting point, every method did not converge after 1,000 iterations. Therefore, we reduced the dimension of the problem to $n=$ and $K=3$ with a maximum of 2,000 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td><img src=\"fig/figure6a.PNG\" width=\"450\" height=\"350\"></td>\n",
    "    <td><img src=\"fig/figure6b.PNG\" width=\"450\" height=\"350\"></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 6.(a) shows the number of iterations required to achieve $\\varepsilon$-accuray for the non-noisy case and Figure 6. (b) shows the number of iterations required to achieve $\\varepsilon$-accuray for the noisy case.\n",
    "\n",
    "For the non-noisy case (Figure 6. (a)), we observe that the APROX family except SGM quickly converges to a wide variety of initial step size choices while SGM converges for a narrow choice of initial step size.\n",
    "\n",
    "Results are similar for proximal and truncated methods in the noisy case (Figure 6. (b)). Bundle method did not show significnat gain in performance compared to proximal point and truncated methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Poisson regression\n",
    "\n",
    "Let $b_i\\in\\mathbb{N}$ be counts as coming from a distribution $p(b|a, x) = \\exp(-e^{\\langle a, x\\rangle})\\exp(b\\langle a, x\\rangle)/b!$, giving loss $f(x;(a,b)) = \\exp(\\langle a, x\\rangle) - b\\langle a, x\\rangle$. We generate the data by first drawing $u\\sim\\sqrt{n}\\cdot\\text{Uni}(\\mathbb{S}^{n-1})$, then drawing $a_i\\overset{\\text{iid}}{\\sim}N(0, (1/n)I_n)$ and $b_i\\sim\\text{Poisson}(e^{\\langle a_i, u\\rangle})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig/figure7.PNG\" width=\"450\" height=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present the results in Figure 7. It is surprising to us that the SGM converges at all on this problem. Importantly, the truncated model, in spite of its substantially easier calculation, enjoys the best convergence among all. Following the truncated model, the proximal point method and the bundle model yield better convergence than SGM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Asi and Duchi's paper \"Stochastic (approximate) proximal point methods\", iterates generated by APROX family converges almost surely when the iterates are bounded almost surely, a condition Asi and Duchi's paper defined as \"stability\". Among the ARPOX family, the stochastic proximal point method and the bundle method satisfy stability, while the stochastic gradient method and the truncated model do not. That is why Asi and Duchi highlight the importance of proper selection of the stochastic optimization methods from APROX famliy. One can expect the stochastic proximal point method and the bundle model to outperform the stochastic gradient method and the truncated model due to stability.\n",
    "\n",
    "However, the results from our experiments were quite different. In all of our examples, the truncated model not only exhibited convergence but also outperformed the stochastic proximal point method and the bundle model. Although not as notable as the truncated method, the stochastic proximal point method and the bundle model showed better performance than the stochastic gradient method. It is very interesting that the truncated model was the best performing model, without theoretical guarantee on stability. Theoretical properties of the truncated model should be further investigated.\n",
    "\n",
    "Finally, we would like to point out that the performance of four methods did not really stand out in many of our experiments and the figures in Asi and Duchi's paper were very tricky to reproduce. For many a cases, none of the four methods converged under 1,000 iterations. The difference stood out only when initial points were chosen properly, most of the time in the vicinity of the optimal points. In order to observe the convergence of APROX famil methods starting from arbitrary initial points, more iteration is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) H. Asi and J. C. Duchi. Stochastic (approximate) proximal point methods: Convergence, optimality, and adaptivity. SIAM J.OPTIM. Vol. 29, No.3, pp. 2257-2290. 2019\n",
    "\n",
    "2) Toulis, P and Airoldi, E. M. Asymptotic and finite-sample properties of estimators based on stochastic gradients. Annals of Statistics, 45(4):1694-1727. 2017\n",
    "\n",
    "3) J. Hiriart-Urruty and C. Lemarechal. Convex Analysis and Minimization Algorithms 1\n",
    "& 2 Springer, New York. 1993.\n",
    "\n",
    "4) C. H. Teo, S. Vishwanthan, A. J. Smola, and Q. V. Le. Bundle methods for regularized\n",
    "risk minimization. Journal of Machine Learning Research, 11:311-365, 2010."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
